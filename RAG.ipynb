{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95feaa36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e10f3865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='지구의 자전 주기는 약 23시간 56분 4초로, 이것을 하루로 계산하면 24시간이 됩니다. 이 자전 주기에 따라서 지구는 자전하는 동안 주변의 태양, 달 및 별들이 동쪽으로 이동하는 것처럼 보입니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 98, 'prompt_tokens': 16, 'total_tokens': 114, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BWvUu1eZMqZkacSiD4uyE6jBLL1gC', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--e1dfcd72-3b75-485b-83af-9adb1a542798-0', usage_metadata={'input_tokens': 16, 'output_tokens': 98, 'total_tokens': 114, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "llm.invoke(\"지구의 자전 주기는?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf68afa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'지구의 자전 주기는 약 24시간, 즉 하루입니다.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"You are an expert in astronomy. Answer the question. <Question>: {input}\")\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "output_parser = StrOutputParser() # str만 출력\n",
    "\n",
    "chain = prompt | llm | output_parser # |로 체인을 구성한답니다 프롬프트 -> 모델 -> invoke\n",
    "chain.invoke({\"input\": \"지구의 자전 주기는?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9572b43b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The word \"미래\" translates to \"future\" in English.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt1 = ChatPromptTemplate.from_template(\"translates {korean_word} to English\")\n",
    "prompt2 = ChatPromptTemplate.from_template(\n",
    "    \"explain {english_word} using oxford dictionary to me in Korean\"\n",
    ")\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "chain1 = prompt1 | llm | StrOutputParser()\n",
    "chain1.invoke({\"korean_word\":\"미래\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34878ea1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'미래는 예상되거나 예상된 시간이나 상황으로, 이후에 오는 시기 또는 미래의 시대를 가리킵니다.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain2 = (\n",
    "    {\"english_word\" : chain1}\n",
    "    | prompt2\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "chain2.invoke({\"korean_word\":\"미래\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f1fe70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'안녕하세요. 제 이름은 홍길동이고, 나이는 30살입니다.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prompt template 모델에 입력하는 입력문\n",
    "# 문장을 입력받아서 문장을 출력할 때\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template_text = \"안녕하세요. 제 이름은 {name}이고, 나이는 {age}살입니다.\"\n",
    "prompt_template = PromptTemplate.from_template(template_text)\n",
    "filled_prompt = prompt_template.format(name=\"홍길동\", age=30)\n",
    "filled_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2ff67b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['age', 'language', 'name'], input_types={}, partial_variables={}, template='안녕하세요. 제 이름은 {name}이고, 나이는 {age}살입니다.\\n\\n아버지를 아버지라 부를 수 없습니다.\\n\\n{language}로 번역해주세요')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combiend_prompt = (\n",
    "    prompt_template\n",
    "    + PromptTemplate.from_template(\"\\n\\n아버지를 아버지라 부를 수 없습니다.\")\n",
    "    + \"\\n\\n{language}로 번역해주세요\"\n",
    ")\n",
    "\n",
    "combiend_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92fb91c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'안녕하세요. 제 이름은 홍길동이고, 나이는 30살입니다.\\n\\n아버지를 아버지라 부를 수 없습니다.\\n\\n영어로 번역해주세요'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combiend_prompt.format(name=\"홍길동\", age=30, language=\"영어\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf15cfe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='이 시스템은 천문학 질문에 답변할 수 있습니다.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='태양계에서 가장 큰 행성은 무엇인가요?', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chatprompttemplate 여러 메세지 입력\n",
    "# 채팅 메세지 리스트형식으로\n",
    "# 역할과 내용 부여\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"이 시스템은 천문학 질문에 답변할 수 있습니다.\"), # llm 역할 정의\n",
    "    (\"user\", \"{user_input}\")\n",
    "])\n",
    "\n",
    "message = chat_prompt.format_messages(user_input=\"태양계에서 가장 큰 행성은 무엇인가요?\")\n",
    "message\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b61a126b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'태양계에서 가장 큰 행성은 목성입니다. 목성은 태양계에서 가장 큰 질량을 가지고 있으며, 지름도 가장 큽니다.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = chat_prompt | llm | StrOutputParser()\n",
    "chain.invoke({\"user_input\" : \"태양계에서 가장 큰 행성은 무엇인가요?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "65673123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='이 시스템은 천문학 질문에 답변할 수 있습니다.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='태양계에서 가장 큰 행성은 무엇인가요?', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# messageprompt template\n",
    "from langchain_core.prompts import SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessagePromptTemplate.from_template(\"이 시스템은 천문학 질문에 답변할 수 있습니다.\"),\n",
    "        HumanMessagePromptTemplate.from_template(\"{user_input}\")\n",
    "    ]\n",
    ")\n",
    "message = chat_prompt.format_messages(user_input=\"태양계에서 가장 큰 행성은 무엇인가요?\")\n",
    "message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "53d825f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n1. 경복궁\\n2. 남산 서울타워\\n3. 제주도 성산일출봉'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import OpenAI\n",
    "llm = OpenAI()\n",
    "llm.invoke(\"한국의 대표적인 관광지 3군데를 추천해주세요\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0a184741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='안녕하세요! 한국의 대표적인 관광지 3군데를 추천해드리겠습니다.\\n\\n1. 경복궁 (Gyeongbokgung Palace) - 서울에 위치한 경복궁은 조선 시대의 궁궐로서 대한민국에서 가장 유명한 궁궐 중 하나입니다. 아름다운 조선 시대의 건축물과 정원을 감상할 수 있으며, 교대식이나 경축행사 등 다양한 체험 프로그램도 제공됩니다.\\n\\n2. 부산 해운대해수욕장 (Haeundae Beach) - 부산에 위치한 해수욕장으로 한국에서 가장 유명하고 인기 있는 해변 중 하나입니다. 푸른 바다와 백사장이 만드는 풀 바캉스 분위기를 즐기며, 주변의 맛집이나 상점도 즐길 수 있습니다.\\n\\n3. 경주 석굴암 (Bulguksa Temple and Seokguram Grotto) - 경주에 위치한 석굴암은 대한민국의 대표적인 사찰로서 석가탑, 불상, 그리고 아름다운 정원 등이 함께 어우러져 있는 곳입니다. 석굴암과 함께 방문하는 범교사와 불교 문화를 느낄 수 있는 곳입니다.\\n\\n위의 관광지들은 한국을 방문하는 여행객들에게 인기있는 명소들입니다. 즐거운 한국 여행 되시길 바랍니다!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 466, 'prompt_tokens': 59, 'total_tokens': 525, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BX1St8Dp3WH3VKuSf5CDnPx6gG2fv', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--dc25b486-ebaa-4d41-99a5-a43aafc9f7e6-0', usage_metadata={'input_tokens': 59, 'output_tokens': 466, 'total_tokens': 525, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI()\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"이 시스템은 여행 전문가입니다.\"),\n",
    "    (\"user\", \"{user_input}\"),\n",
    "])\n",
    "\n",
    "chain = chat_prompt | chat\n",
    "chain.invoke({\"user_input\": \"안녕하세요? 한국의 대표적인 관광지 3군데를 추천해주세요.\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94dc4fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\12wkd\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py:3517: UserWarning: Parameters {'stop', 'frequency_penalty', 'presence_penalty'} should be specified explicitly. Instead they were passed in as part of `model_kwargs` parameter.\n",
      "  if await self.run_code(code, result, async_=asy):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='태양계에서 가장 큰 행성은 목성입니다. 목성은 지름이 약 142,984km로 태양계에서 가장 큰 크기를 자랑하는 행성이며, 대표적인 가스 행성 중 하나입니다.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 75, 'prompt_tokens': 29, 'total_tokens': 104, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BYka9FNHr2a84Cs2qra6rbhH8Qe3i', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--0784efd3-132a-44cd-b99c-faade5e155a1-0' usage_metadata={'input_tokens': 29, 'output_tokens': 75, 'total_tokens': 104, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "# temperature 생성된 텍스트의 다양성을 조정 값이 작으면 예측가능하고 일관된 출력, 값이 크면 다양하고 예측하기 어려움\n",
    "# max tokens 생성할 최대 토큰 수, 텍스트 길이\n",
    "# Top P 다음 출력의 확률값중 상위 P퍼센트만\n",
    "# Frequnecy Penalty, Presence Penalty 빈도와 존재여부에 따라 등장시키는\n",
    "# Stop Sequences 특정단어나 구절이 등장할 경우 생성을 멈춤\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "params = {\n",
    "    \"temperature\" : 0.7,\n",
    "    \"max_tokens\" : 100,\n",
    "}\n",
    "\n",
    "kwargs = {\n",
    "    \"frequency_penalty\": 0.5,\n",
    "    \"presence_penalty\" : 0.5,\n",
    "    \"stop\" : [\"\\n\"]\n",
    "}\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", **params, model_kwargs=kwargs)\n",
    "\n",
    "question = \"태양계에서 가장 큰 행성은 무엇인가요?\"\n",
    "response = model.invoke(input=question)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1936324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='가장 큰 행성은 목' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 29, 'total_tokens': 39, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BYkcR5AOsde83eq4VI7Nmbi7PGHnO', 'service_tier': 'default', 'finish_reason': 'length', 'logprobs': None} id='run--20880a45-8db2-4864-b854-651ebd2c03f7-0' usage_metadata={'input_tokens': 29, 'output_tokens': 10, 'total_tokens': 39, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"temperature\" : 0.7,\n",
    "    \"max_tokens\" : 10,\n",
    "}\n",
    "\n",
    "response = model.invoke(input=question, **params)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "635e39b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='태양계에서 가장 큰 행성은 목성입니다. 목성은 질량, 부피, 지름 등 모든 관점에서 다른 행성들보다 큽니다.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 54, 'prompt_tokens': 58, 'total_tokens': 112, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BYkiPYKWb1OoaHCovFjCIBGxpjjzE', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--f5f6bed0-01bd-45b4-8ffc-16f8ebd59639-0' usage_metadata={'input_tokens': 58, 'output_tokens': 54, 'total_tokens': 112, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "content='태양계에서 가장 큰' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 58, 'total_tokens': 68, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BYkiQtjijUCjdCex0icaCbcculUxV', 'service_tier': 'default', 'finish_reason': 'length', 'logprobs': None} id='run--fbd0ee4f-9044-439e-9caf-b61fb6a60c8c-0' usage_metadata={'input_tokens': 58, 'output_tokens': 10, 'total_tokens': 68, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"이 시스템은 천문학 질문에 답변할 수 있습니다.\"),\n",
    "    (\"user\", \"{user_input}\"),\n",
    "])\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", max_tokens=100)\n",
    "messages = prompt.format_messages(user_input=\"태양계에서 가장 큰 행성은 무엇인가요?\")\n",
    "\n",
    "before_answer = model.invoke(messages)\n",
    "print(before_answer)\n",
    "\n",
    "chain = prompt | model.bind(max_tokens=10)\n",
    "after_answer = chain.invoke({\"user_input\":\"태양계에서 가장 큰 행성은 무엇인가요?\"})\n",
    "print(after_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf824ed6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
